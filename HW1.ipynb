{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cshuler/CEE696_Deep/blob/master/HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5tH-h7ZFtUv",
        "colab_type": "text"
      },
      "source": [
        "CEE 696 HW1\n",
        "\n",
        "The objective of this homework is \n",
        "\n",
        "1) to understand TensorFlow-Keras (tf-keras) input data structure\n",
        "\n",
        "2) run tf-keras with different NN structures and optimizers\n",
        "\n",
        "\n",
        "# HW1 \n",
        "\n",
        "You are running a deep learning company and \"awesome-dl\" has long been your loyal cumstomer. \n",
        "\n",
        "Today \"awesome-dl\" brought a field data set (x coord,y coord, elevation) and asked you to build up a map for any (x coord, y coord). \n",
        "\n",
        "\"awesome-dl\" is a shy person and didn't explain a lot about how the data were aquired.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxYWrr1nFcAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline \n",
        "\n",
        "# import required packages - feel free to add any packages you like\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential # layer-by-layer construction\n",
        "from tensorflow.keras.layers import Dense # dense: fully connected layers\n",
        "from tensorflow.nn import relu, sigmoid # activation functions\n",
        "\n",
        "from scipy.interpolate import griddata # for interpolation on a uniform grid \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGUyYAm3Fo5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.__version__)\n",
        "print(tf.__version__)\n",
        "print(tf.keras.backend.image_data_format()) # channels_last => [channels][rows][cols]."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7LhfUzicHRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fix the random seed for reproducibility\n",
        "np.random.seed(696007)\n",
        "tf.set_random_seed(696007)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmNjukWM9Xqj",
        "colab_type": "text"
      },
      "source": [
        "We got a link to download the data: http://www2.hawaii.edu/~jonghyun/classes/F19/CEE696/files/HW1data.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD_ZvcG49l9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://www2.hawaii.edu/~jonghyun/classes/F19/CEE696/files/HW1data.txt # wget is a Linux command to download through http\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnoIbn9P95R-",
        "colab_type": "text"
      },
      "source": [
        "Please check whether HW1data.txt is on the left panel - **Files** tab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOl0OVqm94XQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.loadtxt('HW1data.txt') # x coord,y coord, elevation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGnZEFbh-Zv1",
        "colab_type": "text"
      },
      "source": [
        "**Q1**) As a data analysist, your first job is always to understand the data - one of the most effective and intuitive ways to check the data is *visualization*. First plot your data sets. You can use ``griddata`` (scipy.interpolate.griddata) to intepolate this scattered data on a uniform grid and plot it using plt.contour and plt.pcolormesh\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKJfVbxR-agd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gATfVfXI-ue8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot x,y coords\n",
        "#plt.figure()\n",
        "#plt.plot(data[:,0],data[:,1],'.')\n",
        "#plt.axis('square')\n",
        "#plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H_osusy-7Ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#xx = np.linspace # complete\n",
        "#yy = np.linspace # complete\n",
        "#XX,YY = np.meshgrid(xx,yy)\n",
        "#elev = griddata(data[:,0:2], data[:,2], (XX, YY), method='cubic') # cubic interpolation\n",
        "#plt.contour(XX, YY, elev, 15, linewidths = 0.5, colors = 'k')\n",
        "#plt.pcolormesh(XX, YY, elev, cmap = plt.get_cmap('rainbow'))\n",
        "#plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myx66Ls8Yc0d",
        "colab_type": "text"
      },
      "source": [
        "**Q2**) Now it is the time to construct your DNN model for map constrcution. \n",
        "\n",
        "\"awesome-dl\" didn't care about overfitting and generalization error, so you want to overfit the data as much as possible\n",
        "\n",
        "Widely used method is to start from a simple model (1~2 hidden layers) and add more layers and neurons until you have satisfactory results. \n",
        "\n",
        "You can change optimizer as well. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjApYc4AaA5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "\n",
        "# add code here \n",
        "\n",
        "model.compile(optimizer='sgd',loss='mean_squared_error',metrics=['mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTxEz4UIYjoC",
        "colab_type": "text"
      },
      "source": [
        "Printout model summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTvEn9TSbqMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9BrRhn2cMFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiHYrDXaaBJN",
        "colab_type": "code",
        "outputId": "7b7d9bd4-e1f6-4173-aeca-b18ed849dc20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "hist = model.fit() # don't use verbose to check the progress.."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-57184741891c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZEZy5C5JRII",
        "colab_type": "text"
      },
      "source": [
        "plot loss function values over the epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiucuHTkClVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(hist.history.keys())\n",
        "# Plot training & validation accuracy values\n",
        "plt.semilogy(hist.history['loss'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('mean_squared_error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1sE32_LI0fs",
        "colab_type": "text"
      },
      "source": [
        "Q3) Check your predicted map below and compare it with direct interpolated map from the data above. Do you think this map can please \"awesome-dl\"?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YuVYMFndm8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prediction\n",
        "xx = np.linspace(0,1,200)\n",
        "yy = np.linspace(0,1,200)\n",
        "XX,YY = np.meshgrid(xx,yy)\n",
        "\n",
        "Xpred = np.hstack((XX.reshape(-1,1),YY.reshape(-1,1)))\n",
        "\n",
        "Ypred = model.predict(Xpred)\n",
        "\n",
        "# plot \n",
        "plt.pcolor(XX,YY,Ypred.reshape(200,200), cmap = 'jet')\n",
        "plt.plot(data[:,0],data[:,1],'.')\n",
        "plt.colorbar()\n",
        "plt.axis('square')\n",
        "plt.title('Prediction')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}